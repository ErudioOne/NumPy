{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "| <img src=\"img/Erudio-logo.png\" alt=\"Erudio logo\" width=\"100\"/>| | Elevate Your Potential with the Power of Artificial Intelligence |\n",
    "|---:|---:|:---|\n",
    "| <div style=\"width:600px\"><img src=\"img/numpylogo.svg\" alt=\"NumPy logo\" width=\"200\"/></div>| <div style=\"width:200px; font-size:20px\">Lesson 6:</div> | <div style=\"width:400px; font-size:20px\">Miscellaneous and Advanced Topics</div>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Miscellaneous and Advanced Topics\n",
    "\n",
    "This module is a little bit of a grab bag of things that do not fit in easlier moduels, and most likely only somewhat advanced users need to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Record Arrays\n",
    "\n",
    "We mention the use of records in NumPy for completeness.  In the last number of years, most of the purpose that would be served by records is better addressed with Pandas DataFrames.  However, Pandas is a very large and complex library, and it may be better to stay with raw NumPy for many purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An `np.record` is simply a way of collecting together several kinds of information within the same fixed-size data segment.  Record arrays are simply arrays, so all the same reshaping, slicing, filtering, broadcasting, etc. that works with other arrays works with record arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Basic NumPy arrays always have elements of a single type.  However, that type can be a compound type.  The types of components of a record (or struct) can mostly be specified in two ways.  Using very short letter/number combinations, or using the NumPy type objects.\n",
    "\n",
    "For example:\n",
    "\n",
    "* b1, i1, i2, i4, i8, u1, u2, u4, u8, f2, f4, f8, c8, c16, a&lt;n&gt; (bytes, ints, unsigned ints, floats, complex and fixed length strings of a given *byte* lengths)\n",
    "* `np.int8`, ..., `np.uint8`, ..., `np.float16`, `np.float32`, `np.float64`, `np.complex64`, etc. (similar but with *bit* sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# a record with a 4 byte int, a 4 byte float, \n",
    "# and 10 bytes of characters (ascii values)\n",
    "arr = np.zeros((2,), dtype=('i4,f4,a10'))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arr[:] = [(1, 5., 'Hello'), (2, 6., 'World')]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Access one field\n",
    "arr['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Perform a reduction on one field of the record array\n",
    "arr['f1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Update values within a field of a record array\n",
    "arr['f1'][0] = 999\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving and Loading Arrays\n",
    "\n",
    "There are actually several different techniques for serializing and deserializing NumPy arrays.  At a basic level, Python `pickle` standard library module will work, but not as efficiently as some more specialized tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NumPy includes several mechanisms for saving internally.  We present the choice that is usually best, `np.savez_compressed()`, but be aware of `np.save()`, `np.savetxt()`, `np.savez()`.  These can be loaded with `np.load()` or `np.loadtxt()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, for more high-performance needs—especially dealing with very large data—investigate [HDF5 for Python](https://www.h5py.org/) and [`joblib.dump()`](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%file tmp/patient-records.csv\n",
    "name,date,weight(kg),height(cm)\n",
    "Alice,2011-01-01,85.1,170\n",
    "Barb,2012-02-02,66.7,160\n",
    "Carla,2013-03-03,29.5,120\n",
    "Dagmar,2014-04-04,64.2,180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "patient_dtype = [(\"name\", \"a10\"),\n",
    "                 (\"visit_date\", 'datetime64[D]'),\n",
    "                 (\"weight\", np.float32),\n",
    "                 (\"height\", np.int16)]\n",
    "\n",
    "data = np.loadtxt(\"tmp/patient-records.csv\", \n",
    "                  skiprows=1, \n",
    "                  delimiter=\",\", \n",
    "                  dtype=patient_dtype,\n",
    "                  converters = {1: np.datetime64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"first row: \", data[0])\n",
    "print(\"all weights: \", data['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# BMI = kg / m**2\n",
    "print(\"BMIs:\", data['weight'] / (data['height']/100.0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Those patients with high BMI\n",
    "print(data[(data['weight'] / (data['height']/100.0)**2) > 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While we illustrated I/O above using record arrays, there is nothing specific to those in the loading and saving mechanisms.  \"Vanilla\" NumPy arrays can equally be saved and loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arr1 = np.random.random(1000).reshape(10, 10, 10)\n",
    "arr2 = np.random.randint(0, 100, 100).reshape(2, 5, 5, 2)\n",
    "np.savez_compressed('tmp/random.npz', normal=arr1, int4d=arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load('tmp/random.npz')\n",
    "print(data.files)\n",
    "print(data['int4d'].shape)\n",
    "print(data['normal'][7, 5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compiled expressions\n",
    "\n",
    "Operations on arrays peformed by NumPy are extremely fast, since they are written in optimized C or Fortran code (or sometimes use Numba to do just-in-time machine code generation with LLVM).\n",
    "\n",
    "However, when you do a series of fast operations, you generally wind up round-tripping back to the much slower Python evaluation loop to dispatch the next operation.  The extra library `numexpr` can help reduce temporary arrays by compiling a string expression and returning a new array. It will also execute in parallel across many cores, where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "\n",
    "arr = np.random.random(100_000_000)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Not necessarily a natural combination of operations, \n",
    "# but several manipulations to illustrate the point\n",
    "%timeit np.sqrt(np.log((np.sin(arr**2) + np.cos(arr**3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Avoid 6 trips back-and-forth between array code and Python interpreter\n",
    "%timeit ne.evaluate('sqrt(log((sin(arr**2) + cos(arr**3))))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`numexpr` supports in-place. Be careful not to run this twice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out_arr = ne.evaluate('sin(arr**2) + cos(arr**3)', out=arr)\n",
    "out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out_arr is arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "This module will ask you to perform several actions with a widely used dataset often provided as a machine learning example.  The UCI ML Breast Cancer Wisconsin (Diagnostic) dataset contains measures of tumors examined for malignancy.\n",
    "\n",
    "We are not going to do machine learning per se in these exercises, but we would like to look at some summaries of the data.  The next cell will load the description of the data.  The actual dataset is contained in `data/wisconsin.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load data/wisconsin.descr\n",
    ".. _breast_cancer_dataset:\n",
    "\n",
    "Breast cancer wisconsin (diagnostic) dataset\n",
    "--------------------------------------------\n",
    "\n",
    "**Data Set Characteristics:**\n",
    "\n",
    "    :Number of Instances: 569\n",
    "\n",
    "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
    "\n",
    "    :Attribute Information:\n",
    "        - radius (mean of distances from center to points on the perimeter)\n",
    "        - texture (standard deviation of gray-scale values)\n",
    "        - perimeter\n",
    "        - area\n",
    "        - smoothness (local variation in radius lengths)\n",
    "        - compactness (perimeter^2 / area - 1.0)\n",
    "        - concavity (severity of concave portions of the contour)\n",
    "        - concave points (number of concave portions of the contour)\n",
    "        - symmetry \n",
    "        - fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "        largest values) of these features were computed for each image,\n",
    "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
    "        13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "        - class:\n",
    "                - WDBC-Malignant\n",
    "                - WDBC-Benign\n",
    "\n",
    "    :Summary Statistics:\n",
    "\n",
    "    ===================================== ====== ======\n",
    "                                           Min    Max\n",
    "    ===================================== ====== ======\n",
    "    radius (mean):                        6.981  28.11\n",
    "    texture (mean):                       9.71   39.28\n",
    "    perimeter (mean):                     43.79  188.5\n",
    "    area (mean):                          143.5  2501.0\n",
    "    smoothness (mean):                    0.053  0.163\n",
    "    compactness (mean):                   0.019  0.345\n",
    "    concavity (mean):                     0.0    0.427\n",
    "    concave points (mean):                0.0    0.201\n",
    "    symmetry (mean):                      0.106  0.304\n",
    "    fractal dimension (mean):             0.05   0.097\n",
    "    radius (standard error):              0.112  2.873\n",
    "    texture (standard error):             0.36   4.885\n",
    "    perimeter (standard error):           0.757  21.98\n",
    "    area (standard error):                6.802  542.2\n",
    "    smoothness (standard error):          0.002  0.031\n",
    "    compactness (standard error):         0.002  0.135\n",
    "    concavity (standard error):           0.0    0.396\n",
    "    concave points (standard error):      0.0    0.053\n",
    "    symmetry (standard error):            0.008  0.079\n",
    "    fractal dimension (standard error):   0.001  0.03\n",
    "    radius (worst):                       7.93   36.04\n",
    "    texture (worst):                      12.02  49.54\n",
    "    perimeter (worst):                    50.41  251.2\n",
    "    area (worst):                         185.2  4254.0\n",
    "    smoothness (worst):                   0.071  0.223\n",
    "    compactness (worst):                  0.027  1.058\n",
    "    concavity (worst):                    0.0    1.252\n",
    "    concave points (worst):               0.0    0.291\n",
    "    symmetry (worst):                     0.156  0.664\n",
    "    fractal dimension (worst):            0.055  0.208\n",
    "    ===================================== ====== ======\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
    "\n",
    "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
    "\n",
    "    :Donor: Nick Street\n",
    "\n",
    "    :Date: November, 1995\n",
    "\n",
    "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
    "https://goo.gl/U2Uwz2\n",
    "\n",
    "Features are computed from a digitized image of a fine needle\n",
    "aspirate (FNA) of a breast mass.  They describe\n",
    "characteristics of the cell nuclei present in the image.\n",
    "\n",
    "Separating plane described above was obtained using\n",
    "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
    "Construction Via Linear Programming.\" Proceedings of the 4th\n",
    "Midwest Artificial Intelligence and Cognitive Science Society,\n",
    "pp. 97-101, 1992], a classification method which uses linear\n",
    "programming to construct a decision tree.  Relevant features\n",
    "were selected using an exhaustive search in the space of 1-4\n",
    "features and 1-3 separating planes.\n",
    "\n",
    "The actual linear program used to obtain the separating plane\n",
    "in the 3-dimensional space is that described in:\n",
    "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
    "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
    "Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server:\n",
    "\n",
    "ftp ftp.cs.wisc.edu\n",
    "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    ".. topic:: References\n",
    "\n",
    "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
    "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
    "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
    "     San Jose, CA, 1993.\n",
    "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
    "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
    "     July-August 1995.\n",
    "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
    "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
    "     163-171.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Figure out how to load the data in a useful way using NumPy.  Then answer the following questions.  The answers are provided with question for you to check, but you need to arrive at them with your own code to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "cancer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Of those observations that have a larger than median value of \"mean radius\", what is the mean and standard deviation of their \"concavity error\"? \n",
    "\n",
    "Answers: \n",
    "* mean=0.036131897\n",
    "* stddev=0.02302538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Mean/standard deviation of high median mean radius\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Among the benign tumors, what is the correlation coefficient between \"mean symmetry\" and \"mean fractal dimension\" (i.e. Pearson product-moment correlation coefficient). \n",
    "\n",
    "Answer: \n",
    "* coefficient=0.41905971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation coefficient between mean symmetry and mean fractal dimension\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which feature in the data shows the highest magnitude variance? \n",
    "\n",
    "Answer: worst area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature with highest variance\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which feature shows the highest normalized standard deviation?  I.e. standard deviation as a percentage of the entire value range of that feature.\n",
    "\n",
    "Answer: benign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest normalized standard deviation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You should verify the last answer; however, it is an artifact of the target field arbitrarily being encoded as 0/1 for False/True.  Disregarding the target, what field answers this question?\n",
    "\n",
    "Answer: worst concave points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Highest normalized standard deviation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "| | Materials licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)  by the authors|\n",
    "|---|---|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
