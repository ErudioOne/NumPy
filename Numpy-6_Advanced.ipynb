{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![NumPy logo](img/numpylogo.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Miscellaneous and Advanced Topics\n",
    "\n",
    "This module is a little bit of a grab bag of things that do not fit in easlier moduels, and most likely only somewhat advanced users need to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Record Arrays\n",
    "\n",
    "We mention the use of records in NumPy for completeness.  In the last number of years, most of the purpose that would be served by records is better addressed with Pandas DataFrames.  However, Pandas is a very large and complex library, and it may be better to stay with raw NumPy for many purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An `np.record` is simply a way of collecting together several kinds of information within the same fixed-size data segment.  Record arrays are simply arrays, so all the same reshaping, slicing, filtering, broadcasting, etc. that works with other arrays works with record arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Basic NumPy arrays always have elements of a single type.  However, that type can be a compound type.  The types of components of a record (or struct) can mostly be specified in two ways.  Using very short letter/number combinations, or using the NumPy type objects.\n",
    "\n",
    "For example:\n",
    "\n",
    "* b1, i1, i2, i4, i8, u1, u2, u4, u8, f2, f4, f8, c8, c16, a&lt;n&gt; (bytes, ints, unsigned ints, floats, complex and fixed length strings of a given *byte* lengths)\n",
    "* `np.int8`, ..., `np.uint8`, ..., `np.float16`, `np.float32`, `np.float64`, `np.complex64`, etc. (similar but with *bit* sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# a record with a 4 byte int, a 4 byte float, \n",
    "# and 10 bytes of characters (ascii values)\n",
    "arr = np.zeros((2,), dtype=('i4,f4,a10'))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arr[:] = [(1, 5., 'Hello'), (2, 6., 'World')]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Access one field\n",
    "arr['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Perform a reduction on one field of the record array\n",
    "arr['f1'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Update values within a field of a record array\n",
    "arr['f1'][0] = 999\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving and Loading Arrays\n",
    "\n",
    "There are actually several different techniques for serializing and deserializing NumPy arrays.  At a basic level, Python `pickle` standard library module will work, but not as efficiently as some more specialized tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NumPy includes several mechanisms for saving internally.  We present the choice that is usually best, `np.savez_compressed()`, but be aware of `np.save()`, `np.savetxt()`, `np.savez()`.  These can be loaded with `np.load()` or `np.loadtxt()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, for more high-performance needs—especially dealing with very large data—investigate [HDF5 for Python](https://www.h5py.org/) and [`joblib.dump()`](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%file tmp/patient-records.csv\n",
    "name,date,weight(kg),height(cm)\n",
    "Alice,2011-01-01,85.1,170\n",
    "Barb,2012-02-02,66.7,160\n",
    "Carla,2013-03-03,29.5,120\n",
    "Dagmar,2014-04-04,64.2,180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "patient_dtype = [(\"name\", \"a10\"),\n",
    "                 (\"visit_date\", 'datetime64[D]'),\n",
    "                 (\"weight\", np.float32),\n",
    "                 (\"height\", np.int16)]\n",
    "\n",
    "data = np.loadtxt(\"tmp/patient-records.csv\", \n",
    "                  skiprows=1, \n",
    "                  delimiter=\",\", \n",
    "                  dtype=patient_dtype,\n",
    "                  converters = {1: np.datetime64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"first row: \", data[0])\n",
    "print(\"all weights: \", data['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# BMI = kg / m**2\n",
    "print(\"BMIs:\", data['weight'] / (data['height']/100.0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Those patients with high BMI\n",
    "print(data[(data['weight'] / (data['height']/100.0)**2) > 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "While we illustrated I/O above using record arrays, there is nothing specific to those in the loading and saving mechanisms.  \"Vanilla\" NumPy arrays can equally be saved and loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arr1 = np.random.random(1000).reshape(10, 10, 10)\n",
    "arr2 = np.random.randint(0, 100, 100).reshape(2, 5, 5, 2)\n",
    "np.savez_compressed('tmp/random.npz', normal=arr1, int4d=arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load('tmp/random.npz')\n",
    "print(data.files)\n",
    "print(data['int4d'].shape)\n",
    "print(data['normal'][7, 5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compiled expressions\n",
    "\n",
    "Operations on arrays peformed by NumPy are extremely fast, since they are written in optimized C or Fortran code (or sometimes use Numba to do just-in-time machine code generation with LLVM).\n",
    "\n",
    "However, when you do a series of fast operations, you generally wind up round-tripping back to the much slower Python evaluation loop to dispatch the next operation.  The extra library `numexpr` can help reduce temporary arrays by compiling a string expression and returning a new array. It will also execute in parallel across many cores, where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "\n",
    "arr = np.random.random(100_000_000)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Not necessarily a natural combination of operations, \n",
    "# but several manipulations to illustrate the point\n",
    "%timeit np.sqrt(np.log((np.sin(arr**2) + np.cos(arr**3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Avoid 6 trips back-and-forth between array code and Python interpreter\n",
    "%timeit ne.evaluate('sqrt(log((sin(arr**2) + cos(arr**3))))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`numexpr` supports in-place. Be careful not to run this twice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out_arr = ne.evaluate('sin(arr**2) + cos(arr**3)', out=arr)\n",
    "out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out_arr is arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "This module will ask you to perform several actions with a widely used dataset often provided as a machine learning example.  The UCI ML Breast Cancer Wisconsin (Diagnostic) dataset contains measures of tumors examined for malignancy.\n",
    "\n",
    "We are not going to do machine learning per se in these exercises, but we would like to look at some summaries of the data.  The next cell will load the description of the data.  The actual dataset is contained in `data/wisconsin.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# %load data/wisconsin.descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Figure out how to load the data in a useful way using NumPy.  Then answer the following questions.  The answers are provided with question for you to check, but you need to arrive at them with your own code to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "cancer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Of those observations that have a larger than median value of \"mean radius\", what is the mean and standard deviation of their \"concavity error\"? \n",
    "\n",
    "Answers: \n",
    "* mean=0.036131897\n",
    "* stddev=0.02302538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Mean/standard deviation of high median mean radius\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Among the benign tumors, what is the correlation coefficient between \"mean symmetry\" and \"mean fractal dimension\" (i.e. Pearson product-moment correlation coefficient). \n",
    "\n",
    "Answer: \n",
    "* coefficient=0.41905971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation coefficient between mean symmetry and mean fractal dimension\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which feature in the data shows the highest magnitude variance? \n",
    "\n",
    "Answer: worst area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature with highest variance\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which feature shows the highest normalized standard deviation?  I.e. standard deviation as a percentage of the entire value range of that feature.\n",
    "\n",
    "Answer: benign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest normalized standard deviation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You should verify the last answer; however, it is an artifact of the target field arbitrarily being encoded as 0/1 for False/True.  Disregarding the target, what field answers this question?\n",
    "\n",
    "Answer: worst concave points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest normalized standard deviation\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
